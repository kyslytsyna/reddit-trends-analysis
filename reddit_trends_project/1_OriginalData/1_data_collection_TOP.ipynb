{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea981881",
   "metadata": {},
   "source": [
    "**Sampling caveat**  \n",
    "Posts were fetched with `subreddit.top(limit=1000)`, i.e. in **score (rank) order**.  \n",
    "Therefore each subreddit’s 1 000 rows represent its highest-scoring content, not its most recent timeline.  \n",
    "Large date gaps (e.g. r/worldnews has no posts after 2023-03) mean newer posts have not yet reached the score level required to enter the all-time top list.  \n",
    "Time-series insights should be limited to the visible date ranges or the data should be recollected using `subreddit.new()` if chronological coverage is required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2c8582-f63a-42e7-ac11-e8725425e407",
   "metadata": {},
   "source": [
    "### Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0900ee1-b9da-4ffb-abf1-b075813360fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated as: anonymous\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=os.getenv('REDDIT_CLIENT_ID'),\n",
    "    client_secret=os.getenv('REDDIT_CLIENT_SECRET'),\n",
    "    user_agent=os.getenv('REDDIT_USER_AGENT')\n",
    ")\n",
    "\n",
    "print(\"Authenticated as:\", reddit.user.me() or \"anonymous\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8c6e79-5750-4d6e-b260-65a717402dd5",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb8da8a5-c622-4402-8996-f2d15c60a458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data saved to CSV files successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define a function to extract posts from a subreddit\n",
    "def get_top_posts(subreddit_name, limit=100):\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    posts_data = []\n",
    "\n",
    "    for post in subreddit.top(limit=limit):  \n",
    "        posts_data.append({\n",
    "            \"title\": post.title,\n",
    "            \"score\": post.score,\n",
    "            \"url\": post.url,\n",
    "            \"created_utc\": post.created_utc,\n",
    "            \"num_comments\": post.num_comments,\n",
    "            \"subreddit\": subreddit_name\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(posts_data)\n",
    "\n",
    "# Collect data from 6 subreddits\n",
    "news_df = get_top_posts(\"news\", limit=500)\n",
    "worldnews_df = get_top_posts(\"worldnews\", limit=500)\n",
    "politics_df = get_top_posts(\"politics\", limit=500)\n",
    "technology_df = get_top_posts(\"technology\", limit=500) \n",
    "worldpolitics_df = get_top_posts(\"worldpolitics\", limit=500)\n",
    "TrueReddit_df = get_top_posts(\"TrueReddit\", limit=500)\n",
    "\n",
    "# Save to CSV files\n",
    "news_df.to_csv(\"news_data.csv\", index=False)\n",
    "worldnews_df.to_csv(\"worldnews_data.csv\", index=False)\n",
    "politics_df.to_csv(\"politics_data.csv\", index=False)\n",
    "technology_df.to_csv(\"technology_data.csv\", index=False)\n",
    "worldpolitics_df.to_csv(\"worldpolitics_data.csv\", index=False)\n",
    "TrueReddit_df.to_csv(\"TrueReddit_data.csv\", index=False)\n",
    "\n",
    "print(\"✅ Data saved to CSV files successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f93028-fa2d-4f03-8985-85c2d0038a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
